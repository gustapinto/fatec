{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a708612-8de3-4cc4-8fa2-765694dcc12a",
   "metadata": {},
   "source": [
    "# Aula 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c51f21c-abd7-462f-a8c9-be8686c605f0",
   "metadata": {},
   "source": [
    "## Conteúdo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f187182-8f74-40c4-9982-78db9fe56c5e",
   "metadata": {},
   "source": [
    "### Bot usando random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55f97f3-c25a-4a46-aa4d-4faa3fed2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: welcome\n",
      "R: how are you doing?\n",
      "R: how are you?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Palavras esperadas\n",
    "welcome_words_input = ('hey', 'hello', 'hi')\n",
    "\n",
    "# Palavras que responderão as esperadas\n",
    "welcome_words_output = ('key', 'hello', 'how are you?',\n",
    "                        'welcome', 'how are you doing?')\n",
    "\n",
    "def welcome_message(text: str) -> str:\n",
    "    # <str>.split() -> gera uma lista a partir do texto, quebrando\n",
    "    #                  as palavras nos espaços ou no delimitador passado\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        # Valida se a palavra é uma das palavras esperadas\n",
    "        #\n",
    "        # <str>.lower() -> converte texto para minusculas\n",
    "        if word.lower() in welcome_words_input:\n",
    "            # random.choice(...) -> escolhe um elemento aleatório da lista\n",
    "            return random.choice(welcome_words_output)\n",
    "\n",
    "\n",
    "print('R:', welcome_message('hey'))\n",
    "print('R:', welcome_message('hello'))\n",
    "print('R:', welcome_message('hi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9928f7c5-5777-43dd-a49f-e1c39f860a7b",
   "metadata": {},
   "source": [
    "### Bot usando semelhança de cossenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "163075a2-01be-489c-be70-776479a0ed25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gustavo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from goose3 import Goose\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "article = Goose().extract('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "article_sentences = nltk.sent_tokenize(article.cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d05038e-a76e-4b8b-a7cc-726ccc8868a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sentence: str) -> str:\n",
    "    '''\n",
    "    Função de pré processamento das sentenças\n",
    "    '''\n",
    "    \n",
    "    sentence_lower = sentence.lower()\n",
    "\n",
    "    tokens = [token.text for token in nlp(sentence) if not (token.is_stop\n",
    "                                                            or token.like_num\n",
    "                                                            or token.is_punct\n",
    "                                                            or token.is_space\n",
    "                                                            or len(token) == 1)]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def answer(user_text: str, threshold: float = 0.25) -> str:\n",
    "    '''\n",
    "    Função que obtém a resposta para um texto do usuário\n",
    "    '''\n",
    "    \n",
    "    preprocessed_sentences = [preprocessing(sentence) for sentence in article_sentences]\n",
    "    preprocessed_user_text = preprocessing(user_text)\n",
    "\n",
    "    # Adiciona o texto do usuário processado ao final das\n",
    "    # sentenças limpas\n",
    "    preprocessed_sentences.append(user_text)\n",
    "\n",
    "    # Instancia vetorizador de TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Vetoriza e transforma as sentenças preprocessadas\n",
    "    vectorized_sentences = vectorizer.fit_transform(preprocessed_sentences)\n",
    "\n",
    "    # Calcula a similaridade de conseno entre a ultima posição (pergunta usuário)\n",
    "    # e as demais sentenças\n",
    "    similarity = cosine_similarity(vectorized_sentences[-1], vectorized_sentences)\n",
    "\n",
    "    # Obtém o indice da penúltima posição (maior corresopndencia)\n",
    "    similarity_index = similarity.argsort()[0][-2]\n",
    "\n",
    "    # Obtém o valor de similaridade\n",
    "    similarity_score = similarity[0][similarity_index]\n",
    "\n",
    "    if similarity_score < threshold:\n",
    "        return 'sorry, no answer was found'\n",
    "\n",
    "    # Acessa a lista de sentenças originais\n",
    "    return article_sentences[similarity_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fdd4276-79d4-4433-ae76-62c8221f63b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: how are you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: key\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: key\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is natural language processing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Natural language processing has its roots in the 1950s.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " who is alan turing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " does artificial intelligence and natural language processign are connected?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: sorry, no answer was found\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Bye! See you soon...\n"
     ]
    }
   ],
   "source": [
    "exit_inputs = ('quit', 'close', 'exit', 'q')\n",
    "\n",
    "while True:\n",
    "    user_text = input()\n",
    "\n",
    "    if user_text.lower() in exit_inputs:\n",
    "        print('Chatbot: Bye! See you soon...')\n",
    "        break\n",
    "\n",
    "    if (msg := welcome_message(user_text)) != None:\n",
    "        print(f'Chatbot: {msg}')\n",
    "    else:\n",
    "        print(f'Chatbot: {answer(user_text)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
